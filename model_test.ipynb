{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= \"data\"\n",
    "normal_files = glob.glob(data_path+'/normal/'+'*.csv')\n",
    "anormal_drift_files = glob.glob(data_path+'/anormal_drift/'+'*.csv')\n",
    "anormal_erratic_files = glob.glob(data_path+'/anormal_erratic/'+'*.csv')\n",
    "anormal_hardover_files = glob.glob(data_path+'/anormal_hardover/'+'*.csv')\n",
    "anormal_spike_files = glob.glob(data_path+'/anormal_spike/'+'*.csv')\n",
    "anormal_stuck_files = glob.glob(data_path+'/anormal_stuck/'+'*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(normal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataReader(path_names):\n",
    "    data_n = pd.DataFrame() #판다스의 데이터프레임 형태로 프레임 생성\n",
    "    for i in path_names:\n",
    "        low_data = pd.read_csv(i)# 판다스 형태로 읽음, 한csv파일씩 읽기 떄문에 다음 라인에서 하나로 합침\n",
    "        data_n = pd.concat([data_n,low_data],ignore_index=True)\n",
    "    return data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_datas = dataReader(normal_files)\n",
    "drift_datas = dataReader(anormal_drift_files)\n",
    "erratic_datas = dataReader(anormal_erratic_files)\n",
    "hardover_datas = dataReader(anormal_hardover_files)\n",
    "spike_datas = dataReader(anormal_spike_files)\n",
    "stuck_datas = dataReader(anormal_stuck_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data shape 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM, LSTM-AE\n",
    "def X_to_XyLSTM_shape(X,ntime_in,ntime_out): #X변형할 시계열 데이터 n_time_in 만큼 하나의 input으로 봄, ntime_out만큼 뒤에꺼를 예측\n",
    "    nsample = len(X) - ntime_in -ntime_out + 1\n",
    "    X_ntime = [0 for _ in range(nsample)]\n",
    "    for i in range(nsample):\n",
    "        X_ntime[i] = X[i:i+ntime_in]\n",
    "    X_train = np.reshape(X_ntime,(nsample,ntime_in,1)) #2차원 배열을 3차원 배열으로\n",
    "    #print('X',X_train.shape)\n",
    "    y_nfuture = [0 for _ in range(nsample)]\n",
    "    for i in range(nsample):\n",
    "        y_nfuture[i] = X[i+ntime_in:i+ntime_in+ntime_out]\n",
    "    y_train = np.array(y_nfuture)\n",
    "    #print('y',y_train.shape)\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (4031990, 10, 1)\n",
      "y (4031990, 1)\n"
     ]
    }
   ],
   "source": [
    "n_time_in = 10 # 10개의 데이터 입력으로 받음\n",
    "ntime_out = 1 # 다음 한개의 데이터 목표값\n",
    "\n",
    "X_LSTM_train, y_LSTM_train = X_to_XyLSTM_shape(normal_datas['value'],n_time_in,ntime_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AE\n",
    "def X_to_XyAE_shape(X,ntime_out): #X변형할 시계열 데이터, ntime_out만큼 뒤에꺼를 예측\n",
    "    nsample = len(X) - ntime_out\n",
    "    X_train = np.array(X[:nsample])\n",
    "    y_train = np.array(X[ntime_out:len(X)])\n",
    "    #print('X',X_train.shape)\n",
    "    #print('y',y_train.shape)\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (4031999,)\n",
      "y (4031999,)\n"
     ]
    }
   ],
   "source": [
    "X_AE_train, y_AE_train = X_to_XyAE_shape(normal_datas['value'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import InputLayer, Dense, LSTM\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "#LSTM_AE 모델\n",
    "LSTM_AE_model = Sequential()\n",
    "\n",
    "LSTM_AE_model.add(LSTM(128, input_shape=(n_time_in, 1)))\n",
    "LSTM_AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(ntime_out))\n",
    "\n",
    "LSTM_AE_model.compile(loss=\"mean_squared_error\",optimizer='adam')\n",
    "\n",
    "#LSTM 모델\n",
    "LSTM_model = Sequential()\n",
    "\n",
    "LSTM_model.add(LSTM(128, input_shape=(n_time_in, 1)))\n",
    "LSTM_model.add(Dense(ntime_out))\n",
    "\n",
    "LSTM_model.compile(loss=\"mean_squared_error\",optimizer='adam')\n",
    "\n",
    "#AE 모델\n",
    "\"\"\"\n",
    "input_dim = 1  # 시계열 데이터의 차원\n",
    "seq_length = 10  # 시계열 데이터의 길이\n",
    "AE_model = Sequential()\n",
    "\n",
    "AE_model.add(InputLayer(input_shape=(1,input_dim)))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(input_dim,activation='linear'))\n",
    "\n",
    "AE_model.compile(loss=\"mean_squared_error\",optimizer='adam')\n",
    "\"\"\"\n",
    "\n",
    "AE_model = Sequential()\n",
    "\n",
    "AE_model.add(InputLayer(input_shape=(1,1)))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(ntime_out,activation='linear'))\n",
    "\n",
    "AE_model.compile(loss=\"mean_squared_error\",optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285446c92d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_AE_model.fit(X_LSTM_train, y_LSTM_train, epochs=1, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285563545d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.fit(X_LSTM_train,y_LSTM_train, epochs=1, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285577ff390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_model.fit(X_AE_train,y_AE_train, epochs=1, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anormal_list = [drift_datas,erratic_datas,hardover_datas,spike_datas,stuck_datas]\n",
    "\n",
    "anormal_dictionary = {\n",
    "    \"drift\":{\n",
    "        \"name\" : \"drift_datas\",\n",
    "        \"pandas\" : drift_datas\n",
    "    }\n",
    "    ,\"erratic\":{\n",
    "        \"name\" : \"erratic_datas\",\n",
    "        \"pandas\" : erratic_datas\n",
    "    }\n",
    "    ,\"hardover\":{\n",
    "        \"name\" : \"hardover_datas\",\n",
    "        \"pandas\" : hardover_datas\n",
    "    }\n",
    "    ,\"spike\":{\n",
    "        \"name\" : \"spike_datas\",\n",
    "        \"pandas\" : spike_datas\n",
    "    }\n",
    "    ,\"stuck\":{\n",
    "        \"name\" : \"stuck_datas\",\n",
    "        \"pandas\" : stuck_datas\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(target,predict):\n",
    "    return (1.0/2.0)*(target-predict)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_matrix(perdict_error,real_error,threshold):\n",
    "    predict_size = len(perdict_error)\n",
    "    #오차행렬 초기화\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0 \n",
    "    Accuracy = np.nan\n",
    "    Recall = np.nan\n",
    "    Percision = np.nan\n",
    "    Specificity = np.nan\n",
    "    for i in range(predict_size):\n",
    "        modelP = 0\n",
    "        modelN = 0\n",
    "        trueP = 0\n",
    "        trueN = 0\n",
    "        # 모델에 대한 P,N\n",
    "        if(perdict_error[i] > threshold):\n",
    "            modelP = 1\n",
    "        else:\n",
    "            modelN = 1\n",
    "        #실제값에 대한 P,N\n",
    "        if(real_error[i] == 1):\n",
    "            trueP = 1\n",
    "        else:\n",
    "            trueN = 1\n",
    "        #오차 행렬 업데이트\n",
    "        if(modelP==1 and trueP == 1):\n",
    "            tp += 1\n",
    "        elif(modelP == 1 and trueN == 1):\n",
    "            fp += 1\n",
    "        elif(modelN == 1 and trueN == 1):\n",
    "            tn += 1\n",
    "        elif(modelN == 1 and trueP == 1):\n",
    "            fn += 1\n",
    "    if(tp+tn+fp+fn != 0):\n",
    "        Accuracy = float(tp+tn)/float(tp+tn+fp+fn) # 전체 예측 중 맞게 예측\n",
    "    if(tp+fn != 0):\n",
    "        Recall = float(tp)/float(tp+fn) # 실제 오류 중 오류라고 예측한 것\n",
    "    if(tp+fp != 0):\n",
    "        Percision = float(tp)/float(tp+fp) # 오류라고 예측한 것 중 실제 오류\n",
    "    if(fp+tn != 0):\n",
    "        Specificity = float(tn)/float(fp+tn) # 오류가 아니라고 예측 한 것 중 정말 오류가 아닌 것\n",
    "    \n",
    "    return Accuracy,Recall,Percision,Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_test,y_predict,test_size,test_data,threshold):\n",
    "    perdict_error =MSE(y_test[:test_size-ntime_out],y_predict[ntime_out:test_size])\n",
    "    perdict_error = perdict_error.reshape(len(perdict_error))\n",
    "    perdict_error.shape\n",
    "\n",
    "    real_error = np.array(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "    real_error.shape\n",
    "\n",
    "    Accuracy,Recall,Percision,Specificity = error_matrix(perdict_error,real_error,threshold)\n",
    "    #print(error_matrix(perdict_error,real_error,threshold))\n",
    "    round2 = lambda number: round(number, 2)\n",
    "    \n",
    "    return np.column_stack((round2(Accuracy*100),round2(Recall*100),round2(Percision*100),round2(Specificity*100))) #%로 바꾸고 소수점 2자리까지 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_AE_evaluate(test_data,threshold):\n",
    "    #print(\"------------LSTM-AE---------------\")\n",
    "    X_LSTMAE_test,y_LSTMAE_test =X_to_XyLSTM_shape(test_data['value'][:10000],n_time_in,ntime_out)\n",
    "    y_LSTMAE_predict = LSTM_AE_model.predict(X_LSTMAE_test,verbose=0)\n",
    "    test_size = len(y_LSTMAE_predict)\n",
    "\n",
    "    \"\"\"\n",
    "    plt.plot(MSE(y_LSTMAE_test[:test_size-ntime_out],y_LSTMAE_predict[ntime_out:test_size])) #y_test는 실제 값 ,y_predict는 예측 값 예측값은 ntime_out 만큼 밀려서 나옴\n",
    "    #plt.plot(y_LSTMAE_test[:test_size-ntime_out]-y_LSTMAE_predict[ntime_out:test_size])\n",
    "    plt.plot(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "    #plt.plot(test_data['value'][n_time_in:test_size]) # test_data['value'][n_time_in:test_size] == y_test[:test_size-ntime_out] 실제 값\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \"\"\"\n",
    "    #print(evaluation(y_LSTMAE_test,y_LSTMAE_predict,test_size,test_data,threshold))\n",
    "    return evaluation(y_LSTMAE_test,y_LSTMAE_predict,test_size,test_data,threshold)\n",
    "    \n",
    "    \n",
    "    \n",
    "def LSTM_evaluate(test_data,threshold):\n",
    "    #print(\"--------------LSTM-----------------\")\n",
    "    X_LSTM_test,y_LSTM_test = X_to_XyLSTM_shape(test_data['value'][:10000],n_time_in,ntime_out)\n",
    "    y_LSTM_predict = LSTM_model.predict(X_LSTM_test,verbose=0)\n",
    "    test_size = len(y_LSTM_predict)\n",
    "    \"\"\"\n",
    "    plt.plot(MSE(y_LSTM_test[:test_size-ntime_out],y_LSTM_predict[ntime_out:test_size])) #y_test는 실제 값 ,y_predict는 예측 값 예측값은 ntime_out 만큼 밀려서 나옴\n",
    "    #plt.plot(y_LSTMAE_test[:test_size-ntime_out]-y_LSTMAE_predict[ntime_out:test_size])\n",
    "    plt.plot(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "    #plt.plot(test_data['value'][n_time_in:test_size]) # test_data['value'][n_time_in:test_size] == y_test[:test_size-ntime_out] 실제 값\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \"\"\"\n",
    "    #print(evaluation(y_LSTM_test,y_LSTM_predict,test_size,test_data,threshold))\n",
    "    return evaluation(y_LSTM_test,y_LSTM_predict,test_size,test_data,threshold)\n",
    "\n",
    "def AE_evaluate(test_data,threshold):\n",
    "    #print(\"----------------AE------------------\")\n",
    "    X_AE_test,y_AE_test = X_to_XyAE_shape(test_data['value'][:10000],ntime_out)\n",
    "    y_AE_predict = AE_model.predict(X_AE_test,verbose=0)\n",
    "    y_AE_predict = y_AE_predict.reshape(len(y_AE_predict))\n",
    "    test_size = len(y_AE_predict)\n",
    "\n",
    "    \"\"\"\n",
    "    plt.plot(MSE(y_AE_test[:test_size-ntime_out],y_AE_predict[ntime_out:test_size])) #y_test는 실제 값 ,y_predict는 예측 값 예측값은 ntime_out 만큼 밀려서 나옴\n",
    "    #plt.plot(y_LSTMAE_test[:test_size-ntime_out]-y_LSTMAE_predict[ntime_out:test_size])\n",
    "    plt.plot(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "    #plt.plot(test_data['value'][n_time_in:test_size]) # test_data['value'][n_time_in:test_size] == y_test[:test_size-ntime_out] 실제 값\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \"\"\"\n",
    "    #print(evaluation(y_AE_test,y_AE_predict,test_size,test_data,threshold))\n",
    "    return evaluation(y_AE_test,y_AE_predict,test_size,test_data,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "anormal_list = [('drift',drift_datas),('erratic',erratic_datas),('hardover',hardover_datas),('spike',spike_datas),('stuck',stuck_datas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_AE_list\n",
      "[[92.93 93.87 79.26 92.65  7.  ]\n",
      " [93.59 93.61 81.37 93.59  7.5 ]\n",
      " [94.17 93.43 83.29 94.39  8.  ]\n",
      " [94.69 93.26 85.12 95.12  8.5 ]\n",
      " [95.12 93.09 86.72 95.73  9.  ]\n",
      " [95.51 92.96 88.16 96.27  9.5 ]]\n",
      "LSTM_AE_list\n",
      "[[88.63 79.72 80.06 92.15  7.  ]\n",
      " [89.15 79.12 81.95 93.11  7.5 ]\n",
      " [89.56 78.66 83.53 93.87  8.  ]\n",
      " [90.02 77.95 85.54 94.79  8.5 ]\n",
      " [90.25 77.53 86.65 95.28  9.  ]\n",
      " [90.44 76.89 87.85 95.8   9.5 ]]\n",
      "LSTM_AE_list\n",
      "[[ 93.86 100.    72.3   92.69   7.  ]\n",
      " [ 94.72 100.    75.22  93.72   7.5 ]\n",
      " [ 95.44 100.    77.86  94.58   8.  ]\n",
      " [ 95.97 100.    79.88  95.2    8.5 ]\n",
      " [ 96.44 100.    81.8   95.76   9.  ]\n",
      " [ 96.86 100.    83.59  96.26   9.5 ]]\n",
      "LSTM_AE_list\n",
      "[[ 92.22 100.     1.15  92.21   7.  ]\n",
      " [ 93.24 100.     1.32  93.24   7.5 ]\n",
      " [ 94.14 100.     1.52  94.14   8.  ]\n",
      " [ 94.84 100.     1.72  94.84   8.5 ]\n",
      " [ 95.47 100.     1.95  95.46   9.  ]\n",
      " [ 96.   100.     2.2   95.99   9.5 ]]\n",
      "LSTM_AE_list\n",
      "[[63.44  0.    0.   92.57  7.  ]\n",
      " [64.1   0.    0.   93.53  7.5 ]\n",
      " [64.68  0.    0.   94.38  8.  ]\n",
      " [65.2   0.    0.   95.14  8.5 ]\n",
      " [65.53  0.    0.   95.62  9.  ]\n",
      " [65.88  0.    0.   96.13  9.5 ]]\n"
     ]
    }
   ],
   "source": [
    "for anormal_type in anormal_list: #anormal_type[0]는 이름 anormal_type[1]는 판다스 데이터\n",
    "    LSTM_AE_list = []\n",
    "    LSTM_list = []\n",
    "    AE_list = []\n",
    "    if (anormal_type[0] == \"drift\"):\n",
    "        threshold = np.arange(7, 10, 0.5)\n",
    "    \"\"\" ##################### 수정 #########################\n",
    "    if (anormal_type[0] == \"drift\"):\n",
    "        threshold = np.arange(7, 10, 0.5)\n",
    "    if (anormal_type[0] == \"drift\"):\n",
    "        threshold = np.arange(7, 10, 0.5)\n",
    "    if (anormal_type[0] == \"drift\"):\n",
    "        threshold = np.arange(7, 10, 0.5)\n",
    "    if (anormal_type[0] == \"drift\"):\n",
    "        threshold = np.arange(7, 10, 0.5)\n",
    "    \"\"\"\n",
    "    for i in threshold:\n",
    "        LSTM_AE_evaluation = LSTM_AE_evaluate(anormal_type[1],i)\n",
    "        LSTM_AE_evaluation = np.append(LSTM_AE_evaluation,i)\n",
    "        LSTM_AE_list.append(LSTM_AE_evaluation)\n",
    "    #LSTM_AE_evaluation = np.append(threshold)\n",
    "    print(\"LSTM_AE_list\")\n",
    "    LSTM_AE_np = np.array(LSTM_AE_list)\n",
    "    print(LSTM_AE_np)\n",
    "    header=\"Accuracy,Recall,Percision,Specificity,Threshold\"\n",
    "    np.savetxt(f\"model_evaluation/LSTM_AE/{anormal_type[0]}.csv\",LSTM_AE_np,delimiter=',',header=header, comments='')\n",
    "    #LSTM_evaluate(anormal_type[1],8.5)\n",
    "    #AE_evaluate(anormal_type[1],8.5)\n",
    "    ######################################LSTM_AE 만 완성#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
