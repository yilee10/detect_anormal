{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= \"data\"\n",
    "normal_files = glob.glob(data_path+'/normal/'+'*.csv')\n",
    "anormal_drift_files = glob.glob(data_path+'/anormal_drift/'+'*.csv')\n",
    "anormal_erratic_files = glob.glob(data_path+'/anormal_erratic/'+'*.csv')\n",
    "anormal_hardover_files = glob.glob(data_path+'/anormal_hardover/'+'*.csv')\n",
    "anormal_spike_files = glob.glob(data_path+'/anormal_spike/'+'*.csv')\n",
    "anormal_stuck_files = glob.glob(data_path+'/anormal_stuck/'+'*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(normal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataReader(path_names):\n",
    "    data_n = pd.DataFrame() #판다스의 데이터프레임 형태로 프레임 생성\n",
    "    for i in path_names:\n",
    "        low_data = pd.read_csv(i)# 판다스 형태로 읽음, 한csv파일씩 읽기 떄문에 다음 라인에서 하나로 합침\n",
    "        data_n = pd.concat([data_n,low_data],ignore_index=True)\n",
    "    return data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_datas = dataReader(normal_files)\n",
    "drift_datas = dataReader(anormal_drift_files)\n",
    "erratic_datas = dataReader(anormal_erratic_files)\n",
    "hardover_datas = dataReader(anormal_hardover_files)\n",
    "spike_datas = dataReader(anormal_spike_files)\n",
    "stuck_datas = dataReader(anormal_stuck_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data shape 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM, LSTM-AE\n",
    "def X_to_XyLSTM_shape(X,ntime_in,ntime_out): #X변형할 시계열 데이터 n_time_in 만큼 하나의 input으로 봄, ntime_out만큼 뒤에꺼를 예측\n",
    "    nsample = len(X) - ntime_in -ntime_out + 1\n",
    "    X_ntime = [0 for _ in range(nsample)]\n",
    "    for i in range(nsample):\n",
    "        X_ntime[i] = X[i:i+ntime_in]\n",
    "    X_train = np.reshape(X_ntime,(nsample,ntime_in,1)) #2차원 배열을 3차원 배열으로\n",
    "    #print('X',X_train.shape)\n",
    "    y_nfuture = [0 for _ in range(nsample)]\n",
    "    for i in range(nsample):\n",
    "        y_nfuture[i] = X[i+ntime_in:i+ntime_in+ntime_out]\n",
    "    y_train = np.array(y_nfuture)\n",
    "    #print('y',y_train.shape)\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (4031990, 10, 1)\n",
      "y (4031990, 1)\n"
     ]
    }
   ],
   "source": [
    "n_time_in = 10 # 10개의 데이터 입력으로 받음\n",
    "ntime_out = 1 # 다음 한개의 데이터 목표값\n",
    "\n",
    "X_LSTM_train, y_LSTM_train = X_to_XyLSTM_shape(normal_datas['value'],n_time_in,ntime_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AE\n",
    "def X_to_XyAE_shape(X,ntime_out): #X변형할 시계열 데이터, ntime_out만큼 뒤에꺼를 예측\n",
    "    nsample = len(X) - ntime_out\n",
    "    X_train = np.array(X[:nsample])\n",
    "    y_train = np.array(X[ntime_out:len(X)])\n",
    "    #print('X',X_train.shape)\n",
    "    #print('y',y_train.shape)\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (4031999,)\n",
      "y (4031999,)\n"
     ]
    }
   ],
   "source": [
    "X_AE_train, y_AE_train = X_to_XyAE_shape(normal_datas['value'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import InputLayer, Dense, LSTM\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "#LSTM_AE 모델\n",
    "LSTM_AE_model = Sequential()\n",
    "\n",
    "LSTM_AE_model.add(LSTM(128, input_shape=(n_time_in, 1)))\n",
    "LSTM_AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(ntime_out))\n",
    "\n",
    "LSTM_AE_model.compile(loss=\"mean_squared_error\",optimizer='adam')\n",
    "\n",
    "#LSTM 모델\n",
    "LSTM_model = Sequential()\n",
    "\n",
    "LSTM_model.add(LSTM(128, input_shape=(n_time_in, 1)))\n",
    "LSTM_model.add(Dense(ntime_out))\n",
    "\n",
    "LSTM_model.compile(loss=\"mean_squared_error\",optimizer='adam')\n",
    "\n",
    "#AE 모델\n",
    "\"\"\"\n",
    "input_dim = 1  # 시계열 데이터의 차원\n",
    "seq_length = 10  # 시계열 데이터의 길이\n",
    "AE_model = Sequential()\n",
    "\n",
    "AE_model.add(InputLayer(input_shape=(1,input_dim)))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(input_dim,activation='linear'))\n",
    "\n",
    "AE_model.compile(loss=\"mean_squared_error\",optimizer='adam')\n",
    "\"\"\"\n",
    "\n",
    "AE_model = Sequential()\n",
    "\n",
    "AE_model.add(InputLayer(input_shape=(1,1)))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(ntime_out,activation='linear'))\n",
    "\n",
    "AE_model.compile(loss=\"mean_squared_error\",optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285446c92d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_AE_model.fit(X_LSTM_train, y_LSTM_train, epochs=1, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285563545d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.fit(X_LSTM_train,y_LSTM_train, epochs=1, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285577ff390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_model.fit(X_AE_train,y_AE_train, epochs=1, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anormal_list = [drift_datas,erratic_datas,hardover_datas,spike_datas,stuck_datas]\n",
    "\n",
    "anormal_dictionary = {\n",
    "    \"drift\":{\n",
    "        \"name\" : \"drift_datas\",\n",
    "        \"pandas\" : drift_datas\n",
    "    }\n",
    "    ,\"erratic\":{\n",
    "        \"name\" : \"erratic_datas\",\n",
    "        \"pandas\" : erratic_datas\n",
    "    }\n",
    "    ,\"hardover\":{\n",
    "        \"name\" : \"hardover_datas\",\n",
    "        \"pandas\" : hardover_datas\n",
    "    }\n",
    "    ,\"spike\":{\n",
    "        \"name\" : \"spike_datas\",\n",
    "        \"pandas\" : spike_datas\n",
    "    }\n",
    "    ,\"stuck\":{\n",
    "        \"name\" : \"stuck_datas\",\n",
    "        \"pandas\" : stuck_datas\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(target,predict):\n",
    "    return (1.0/2.0)*(target-predict)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_matrix(perdict_error,real_error,threshold):\n",
    "    predict_size = len(perdict_error)\n",
    "    #오차행렬 초기화\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0 \n",
    "    Accuracy = np.nan\n",
    "    Recall = np.nan\n",
    "    Percision = np.nan\n",
    "    Specificity = np.nan\n",
    "    for i in range(predict_size):\n",
    "        modelP = 0\n",
    "        modelN = 0\n",
    "        trueP = 0\n",
    "        trueN = 0\n",
    "        # 모델에 대한 P,N\n",
    "        if(perdict_error[i] > threshold):\n",
    "            modelP = 1\n",
    "        else:\n",
    "            modelN = 1\n",
    "        #실제값에 대한 P,N\n",
    "        if(real_error[i] == 1):\n",
    "            trueP = 1\n",
    "        else:\n",
    "            trueN = 1\n",
    "        #오차 행렬 업데이트\n",
    "        if(modelP==1 and trueP == 1):\n",
    "            tp += 1\n",
    "        elif(modelP == 1 and trueN == 1):\n",
    "            fp += 1\n",
    "        elif(modelN == 1 and trueN == 1):\n",
    "            tn += 1\n",
    "        elif(modelN == 1 and trueP == 1):\n",
    "            fn += 1\n",
    "    if(tp+tn+fp+fn != 0):\n",
    "        Accuracy = float(tp+tn)/float(tp+tn+fp+fn) # 전체 예측 중 맞게 예측\n",
    "    if(tp+fn != 0):\n",
    "        Recall = float(tp)/float(tp+fn) # 실제 오류 중 오류라고 예측한 것\n",
    "    if(tp+fp != 0):\n",
    "        Percision = float(tp)/float(tp+fp) # 오류라고 예측한 것 중 실제 오류\n",
    "    if(fp+tn != 0):\n",
    "        Specificity = float(tn)/float(fp+tn) # 오류가 아니라고 예측 한 것 중 정말 오류가 아닌 것\n",
    "    \n",
    "    return Accuracy,Recall,Percision,Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_test,y_predict,test_size,test_data,threshold):\n",
    "    perdict_error =MSE(y_test[:test_size-ntime_out],y_predict[ntime_out:test_size])\n",
    "    perdict_error = perdict_error.reshape(len(perdict_error))\n",
    "    perdict_error.shape\n",
    "\n",
    "    real_error = np.array(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "    real_error.shape\n",
    "\n",
    "    Accuracy,Recall,Percision,Specificity = error_matrix(perdict_error,real_error,threshold)\n",
    "    #print(error_matrix(perdict_error,real_error,threshold))\n",
    "\n",
    "    return np.column_stack((Accuracy,Recall,Percision,Specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(anormal_dictionary,n_time_in,ntime_out):\n",
    "    LSTM_AE_list = np.array([])\n",
    "    LSTM_list = np.array([])\n",
    "    AE_list = np.array([])\n",
    "    for anormal_data in anormal_dictionary:\n",
    "\n",
    "        # 평가 threshold\n",
    "        if(anormal_dictionary[anormal_data]['name']=='drift_datas'): #threshold 범위 정함8~10\n",
    "            threshold = 8.5\n",
    "        if(anormal_dictionary[anormal_data]['name']=='erratic_datas'):\n",
    "            threshold = 7\n",
    "        if(anormal_dictionary[anormal_data]['name']=='hardover_datas'):\n",
    "            threshold = 50\n",
    "        if(anormal_dictionary[anormal_data]['name']=='spike_datas'):\n",
    "            threshold = 1000\n",
    "        if(anormal_dictionary[anormal_data]['name']=='stuck_datas'):\n",
    "            threshold = 1\n",
    "\n",
    "        print(\"++++++++++++++++++++++++++++++++++++\")\n",
    "        print(anormal_dictionary[anormal_data]['name'],threshold)\n",
    "        test_data = anormal_dictionary[anormal_data]['pandas']\n",
    "\n",
    "        # 모델별 평가\n",
    "        print(\"------------LSTM-AE---------------\")\n",
    "        X_LSTMAE_test,y_LSTMAE_test =X_to_XyLSTM_shape(test_data['value'][:10000],n_time_in,ntime_out)\n",
    "        y_LSTMAE_predict = LSTM_AE_model.predict(X_LSTMAE_test,verbose=0)\n",
    "        test_size = len(y_LSTMAE_predict)\n",
    "\n",
    "        \"\"\"\n",
    "        plt.plot(MSE(y_LSTMAE_test[:test_size-ntime_out],y_LSTMAE_predict[ntime_out:test_size])) #y_test는 실제 값 ,y_predict는 예측 값 예측값은 ntime_out 만큼 밀려서 나옴\n",
    "        #plt.plot(y_LSTMAE_test[:test_size-ntime_out]-y_LSTMAE_predict[ntime_out:test_size])\n",
    "        plt.plot(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "        #plt.plot(test_data['value'][n_time_in:test_size]) # test_data['value'][n_time_in:test_size] == y_test[:test_size-ntime_out] 실제 값\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \"\"\"\n",
    "        LSTM_AEevaluation= evaluation(y_LSTMAE_test,y_LSTMAE_predict,test_size,test_data,threshold)\n",
    "        LSTM_AEevaluation = np.append(LSTM_AEevaluation,threshold)\n",
    "        print(LSTM_AEevaluation)\n",
    "        LSTM_AE_list = np.append(LSTM_AE_list,LSTM_AEevaluation)\n",
    "        print(LSTM_AE_list)\n",
    "\n",
    "        print(\"--------------LSTM-----------------\")\n",
    "        X_LSTM_test,y_LSTM_test = X_to_XyLSTM_shape(test_data['value'][:10000],n_time_in,ntime_out)\n",
    "        y_LSTM_predict = LSTM_model.predict(X_LSTM_test,verbose=0)\n",
    "        test_size = len(y_LSTM_predict)\n",
    "        \"\"\"\n",
    "        plt.plot(MSE(y_LSTM_test[:test_size-ntime_out],y_LSTM_predict[ntime_out:test_size])) #y_test는 실제 값 ,y_predict는 예측 값 예측값은 ntime_out 만큼 밀려서 나옴\n",
    "        #plt.plot(y_LSTMAE_test[:test_size-ntime_out]-y_LSTMAE_predict[ntime_out:test_size])\n",
    "        plt.plot(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "        #plt.plot(test_data['value'][n_time_in:test_size]) # test_data['value'][n_time_in:test_size] == y_test[:test_size-ntime_out] 실제 값\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \"\"\"\n",
    "        LSTM_evaluation = evaluation(y_LSTM_test,y_LSTM_predict,test_size,test_data,threshold)\n",
    "        LSTM_evaluation = np.append(LSTM_evaluation,threshold)\n",
    "        print(LSTM_evaluation)\n",
    "        LSTM_list = np.append(LSTM_list,LSTM_evaluation)\n",
    "        print(LSTM_list)\n",
    "\n",
    "        print(\"----------------AE------------------\")\n",
    "        X_AE_test,y_AE_test = X_to_XyAE_shape(test_data['value'][:10000],ntime_out)\n",
    "        y_AE_predict = AE_model.predict(X_AE_test,verbose=0)\n",
    "        y_AE_predict = y_AE_predict.reshape(len(y_AE_predict))\n",
    "        test_size = len(y_AE_predict)\n",
    "\n",
    "        \"\"\"\n",
    "        plt.plot(MSE(y_AE_test[:test_size-ntime_out],y_AE_predict[ntime_out:test_size])) #y_test는 실제 값 ,y_predict는 예측 값 예측값은 ntime_out 만큼 밀려서 나옴\n",
    "        #plt.plot(y_LSTMAE_test[:test_size-ntime_out]-y_LSTMAE_predict[ntime_out:test_size])\n",
    "        plt.plot(test_data['error'][n_time_in:test_size+n_time_in-ntime_out])\n",
    "        #plt.plot(test_data['value'][n_time_in:test_size]) # test_data['value'][n_time_in:test_size] == y_test[:test_size-ntime_out] 실제 값\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \"\"\"\n",
    "        AE_evaluation = evaluation(y_AE_test,y_AE_predict,test_size,test_data,threshold)\n",
    "        AE_evaluation = np.append(AE_evaluation,threshold)\n",
    "        print(AE_evaluation)\n",
    "        AE_list = np.append(AE_list,AE_evaluation)\n",
    "        print(AE_list)\n",
    "    \n",
    "    header = \"Name,Accuracy,Recall,Percision,Specificity,Threshold\"\n",
    "    np.savetxt(f\"model_evaluation/LSTMAE_evaluation.csv\",LSTM_AE_list,delimiter=',',header=header,comments='')\n",
    "    np.savetxt(f\"model_evaluation/LSTM_evaluation.csv\",LSTM_list,delimiter=',',header=header,comments='')\n",
    "    np.savetxt(f\"model_evaluation/AE_evaluation.csv\",AE_list,delimiter=',',header=header,comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++\n",
      "drift_datas 8.5\n",
      "------------LSTM-AE---------------\n",
      "[0.94694164 0.9326087  0.85119048 0.95122903 8.5       ]\n",
      "[0.94694164 0.9326087  0.85119048 0.95122903 8.5       ]\n",
      "--------------LSTM-----------------\n",
      "[0.94674142 0.92173913 0.85760518 0.95422031 8.5       ]\n",
      "[0.94674142 0.92173913 0.85760518 0.95422031 8.5       ]\n",
      "----------------AE------------------\n",
      "[0.88087618 0.62217391 0.81631489 0.95817095 8.5       ]\n",
      "[0.88087618 0.62217391 0.81631489 0.95817095 8.5       ]\n",
      "++++++++++++++++++++++++++++++++++++\n",
      "erratic_datas 7\n",
      "------------LSTM-AE---------------\n",
      "[0.8862749  0.79717314 0.80056778 0.92149742 7.        ]\n",
      "[0.94694164 0.9326087  0.85119048 0.95122903 8.5        0.8862749\n",
      " 0.79717314 0.80056778 0.92149742 7.        ]\n",
      "--------------LSTM-----------------\n",
      "[0.89208129 0.80388693 0.81308077 0.9269451  7.        ]\n",
      "[0.94674142 0.92173913 0.85760518 0.95422031 8.5        0.89208129\n",
      " 0.80388693 0.81308077 0.9269451  7.        ]\n",
      "----------------AE------------------\n",
      "[0.79005801 0.44064812 0.70998865 0.92862132 7.        ]\n",
      "[0.88087618 0.62217391 0.81631489 0.95817095 8.5        0.79005801\n",
      " 0.44064812 0.70998865 0.92862132 7.        ]\n",
      "++++++++++++++++++++++++++++++++++++\n",
      "hardover_datas 50\n",
      "------------LSTM-AE---------------\n",
      "[ 0.99759736  0.985625    0.99936629  0.9998808  50.        ]\n",
      "[ 0.94694164  0.9326087   0.85119048  0.95122903  8.5         0.8862749\n",
      "  0.79717314  0.80056778  0.92149742  7.          0.99759736  0.985625\n",
      "  0.99936629  0.9998808  50.        ]\n",
      "--------------LSTM-----------------\n",
      "[ 0.99809791  0.991875    0.99623352  0.99928478 50.        ]\n",
      "[ 0.94674142  0.92173913  0.85760518  0.95422031  8.5         0.89208129\n",
      "  0.80388693  0.81308077  0.9269451   7.          0.99809791  0.991875\n",
      "  0.99623352  0.99928478 50.        ]\n",
      "----------------AE------------------\n",
      "[ 0.96979396  0.816875    0.99316109  0.99892832 50.        ]\n",
      "[ 0.88087618  0.62217391  0.81631489  0.95817095  8.5         0.79005801\n",
      "  0.44064812  0.70998865  0.92862132  7.          0.96979396  0.816875\n",
      "  0.99316109  0.99892832 50.        ]\n",
      "++++++++++++++++++++++++++++++++++++\n",
      "spike_datas 1000\n",
      "------------LSTM-AE---------------\n",
      "[   1.    1.    1.    1. 1000.]\n",
      "[9.46941636e-01 9.32608696e-01 8.51190476e-01 9.51229028e-01\n",
      " 8.50000000e+00 8.86274902e-01 7.97173145e-01 8.00567779e-01\n",
      " 9.21497416e-01 7.00000000e+00 9.97597357e-01 9.85625000e-01\n",
      " 9.99366286e-01 9.99880796e-01 5.00000000e+01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+03]\n",
      "--------------LSTM-----------------\n",
      "[   1.    1.    1.    1. 1000.]\n",
      "[9.46741416e-01 9.21739130e-01 8.57605178e-01 9.54220315e-01\n",
      " 8.50000000e+00 8.92081289e-01 8.03886926e-01 8.13080772e-01\n",
      " 9.26945104e-01 7.00000000e+00 9.98097908e-01 9.91875000e-01\n",
      " 9.96233522e-01 9.99284778e-01 5.00000000e+01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+03]\n",
      "----------------AE------------------\n",
      "[9.9879976e-01 0.0000000e+00 0.0000000e+00 9.9969967e-01 1.0000000e+03]\n",
      "[8.80876175e-01 6.22173913e-01 8.16314889e-01 9.58170953e-01\n",
      " 8.50000000e+00 7.90058012e-01 4.40648116e-01 7.09988649e-01\n",
      " 9.28621316e-01 7.00000000e+00 9.69793959e-01 8.16875000e-01\n",
      " 9.93161094e-01 9.98928316e-01 5.00000000e+01 9.98799760e-01\n",
      " 0.00000000e+00 0.00000000e+00 9.99699670e-01 1.00000000e+03]\n",
      "++++++++++++++++++++++++++++++++++++\n",
      "stuck_datas 1\n",
      "------------LSTM-AE---------------\n",
      "[0.48263089 0.42729876 0.28507748 0.50803389 1.        ]\n",
      "[9.46941636e-01 9.32608696e-01 8.51190476e-01 9.51229028e-01\n",
      " 8.50000000e+00 8.86274902e-01 7.97173145e-01 8.00567779e-01\n",
      " 9.21497416e-01 7.00000000e+00 9.97597357e-01 9.85625000e-01\n",
      " 9.99366286e-01 9.99880796e-01 5.00000000e+01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+03\n",
      " 4.82630894e-01 4.27298759e-01 2.85077478e-01 5.08033888e-01\n",
      " 1.00000000e+00]\n",
      "--------------LSTM-----------------\n",
      "[0.48833717 0.42729876 0.28856897 0.51635992 1.        ]\n",
      "[9.46741416e-01 9.21739130e-01 8.57605178e-01 9.54220315e-01\n",
      " 8.50000000e+00 8.92081289e-01 8.03886926e-01 8.13080772e-01\n",
      " 9.26945104e-01 7.00000000e+00 9.98097908e-01 9.91875000e-01\n",
      " 9.96233522e-01 9.99284778e-01 5.00000000e+01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+03\n",
      " 4.88337171e-01 4.27298759e-01 2.88568973e-01 5.16359918e-01\n",
      " 1.00000000e+00]\n",
      "----------------AE------------------\n",
      "[0.56261252 0.42798223 0.34422046 0.62459831 1.        ]\n",
      "[8.80876175e-01 6.22173913e-01 8.16314889e-01 9.58170953e-01\n",
      " 8.50000000e+00 7.90058012e-01 4.40648116e-01 7.09988649e-01\n",
      " 9.28621316e-01 7.00000000e+00 9.69793959e-01 8.16875000e-01\n",
      " 9.93161094e-01 9.98928316e-01 5.00000000e+01 9.98799760e-01\n",
      " 0.00000000e+00 0.00000000e+00 9.99699670e-01 1.00000000e+03\n",
      " 5.62612523e-01 4.27982234e-01 3.44220464e-01 6.24598306e-01\n",
      " 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "draw_graph(anormal_dictionary,n_time_in,ntime_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
